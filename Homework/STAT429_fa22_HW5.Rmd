---
title: "HW 05"
author: "Name: Paul Holaway, NetID: paulch2  "
date: 'Due: 9/29/2022 11:59pm'
output: pdf_document
header-includes:
  - \usepackage{pdfpages}
---


```{r setup, include=FALSE}
knitr::opts_chunk
library(xts)
library(astsa)
```

* Unless stated otherwise,  $W_t$ is a white noise process with variance $\sigma_w^2$. 
  + ($W_t$ are independent with zero means and variance $\sigma_w^2$.)
* Show your full work to receive full credit. 



### Question 1.

For an MA(1), $X_t=W_t+\theta W_{t-1}$, show that $|\rho_x (1)|\leq 1/2$ for any number $\theta$. For which values of $\theta$ does $\rho_x(1)$ attain its maximum and minimum?

$$
\gamma_X(s,t)=Cov(W_s+\theta W_{s-1},W_t+\theta W_{t-1})
$$
$$
=Cov(W_s,W_t)+\theta Cov(W_{s-1},W_t)+\theta Cov(W_s,W_{t-1})+\theta^2Cov(W_{s-1},W_{t-1})
$$

1. $h=0 \implies \gamma_X(h)=\sigma^2_w+0+0+\theta\sigma^2_w=\sigma^2_w(1+\theta^2)$
2. $h=1 \implies \gamma_X(h)=0+\theta\sigma^2_w+0+0=\theta\sigma^2_w$
3. $h=2 \implies \gamma_X(h)=0+0+0+0=0$

$$
\gamma_X(h)=\begin{cases} \sigma^2_w(1+\theta^2) &; h=0 \\ \theta\sigma^2_w &; h=1 \\ 0 &; h \ge 2 \end{cases}
$$
$$
\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)} \implies \rho_X(h)=\begin{cases} 1 &; h=0 \\ \frac{\theta}{1+\theta^2} &; h=1 \\ 0 &; h \ge 2 \end{cases}
$$
$$
\rho_X(1)=\frac{\theta}{1+\theta^2}\rightarrow\rho^{'}_X=\frac{1-\theta^2}{(1+\theta^2)^2}
$$
There are no domain restrictions in the denominator as it can never be 0.
$$
1-\theta^2=0\implies\theta^2=1\implies\theta=\pm1
$$

1. $\theta=1$

$$
\rho_X(1)=\frac{1}{1+1}=\frac{1}{2}
$$

\newpage

2. $\theta=-1$

$$
\rho_X(1)=\frac{-1}{1+1}=-\frac{1}{2}
$$
When setting the lag ($h$) equal to 1 in $\rho_X(h)$ and taking the derivative, we find that there are two critical points of the function at $\pm 1$. When plugging those two values into $\rho_X(h)$ we get $\frac{1}{2}$ and $-\frac{1}{2}$. With having no domain restrictions for $\theta$ as the denominator for $\rho_X(1)$ cannot be 0, we can conclude that $|\rho_X(h)| \le \frac{1}{2}$ $\forall \theta$.

- Maximum of $\rho_X(1)=\frac{1}{2}$ at $\theta=1$.
- Minimum of $\rho_X(1)=-\frac{1}{2}$ at $\theta=-1$.

---

### Question 2. 

Calculate and sketch the autocorrelation functions for each of the following AR(1) models. Plot for sufficient lags that the autocorrelation function has nearly died out.

$$
\rho_X(h)=Cov(X_{t-h},X_t)=Cov(\sum_{j=0}^\infty\phi^j,W_{t+h-j},\sum_{k=0}^\infty\phi^kW_{t-k})
$$
$$
=Cov(\phi^hW_t+\phi^{h+1}W_{t-1}+\ldots,W_t+\phi W_{t-1}+\ldots)
$$
$$
=\phi^hVar(W_t)+\phi^{h+1}\phi Var(W_{t-1})+\phi^{h+2}\phi^2Var(W_{t-2})+\ldots
$$
$$
=(\phi^h+\phi^{h+2}+\phi^{h+4}+\ldots)\sigma^2_w=\phi^h(1+\phi^2+\phi^4+\ldots)\sigma^2_w
$$
$$
\implies\gamma_X(h)=\phi^h\frac{\sigma^2_w}{1-\phi^2}
$$
$$
\rho_X(h)=\frac{\gamma_X(h)}{\gamma_X(0)}=\phi^h
$$

(a) $\phi=0.6$

$$
\boxed{\rho_X(h)=0.6^h}
$$
```{r}
set.seed(314439)
data2a = rep(0,51)
for(i in 1:51){
  data2a[i] = (0.6)^(i-1)
}
plot(data2a, pch = 20, xlab = "Lag", ylab = expression(rho[X](h)), 
      main = expression(AR(1)~~~phi==0.6))
```

(b) $\phi=-0.6$

$$
\boxed{\rho_X(h)=(-0.6)^h}
$$
```{r}
set.seed(314439)
data2b = rep(0,51)
for(i in 1:51){
  data2b[i] = (-0.6)^(i-1)
}
plot(data2b, pch = 20, xlab = "Lag", ylab = expression(rho[X](h)), 
      main = expression(AR(1)~~~phi==-0.6))
```

---

### Question 3. 

Suppose that $\{Y_t\}$ is an AR(1) process with $-1<\phi<+1$.

(a) Find the autocovariance function for $V_t=\nabla Y_t = Y_t- Y_{t-1}$ in terms of $\phi$ and $\sigma_W^2$.

$$
\gamma_V(s,t)=Cov(Y_s-Y_{s-1},Y_t-Y_{t-1})
$$
$$
=Cov(Y_s,Y_t)-Cov(Y_{s-1},Y_t)-Cov(Y_s,Y_{t-1})+Cov(Y_{s-1},Y_{t-1})
$$
$$
=\frac{\phi^{|s-t|}\sigma^2_w}{1-\phi^2}+\frac{\phi^{|s-t+1|}\sigma^2_w}{1-\phi^2}+\frac{\phi^{|s-t-1|}\sigma^2_w}{1-\phi^2}+\frac{\phi^{|s-t|}\sigma^2_w}{1-\phi^2}=\frac{\phi^h\sigma^2_w-\phi^{|h+1|}\sigma^2_w-\phi^{|h-1|}\sigma^2_w+\phi^h\sigma^2_w}{1-\phi^2}
$$
$$
\implies\boxed{\gamma_V(h)=\frac{\sigma^2_w(2\phi^h-\phi^{|h+1|}-\phi^{|h-1|})}{1-\phi^2}}
$$

\newpage

(b) In particular, show that $Var(V_t)=2\sigma_W^2/(1+\phi)$.

$$
Var(V_t)=\frac{\sigma^2_w(2\phi^0-\phi-\phi)}{1-\phi^2}=\frac{2\sigma^2_w(1-\phi)}{(1+\phi)(1-\phi)}
$$
$$
\implies\boxed{Var(V_t)=\frac{2\sigma^2_w}{1+\phi}}
$$

---

### Question 4. 

Let $|\phi|<1$ be a constant. Consider the process $X_0=W_0$, and

$$X_t = \phi X_{t-1}+W_t, \quad t=1,2,\dots$$

(a) Show that $X_t = \sum_{j=0}^{t}\phi^j W_{t-j}$ for any $t=0,1,\dots$.

$$
X_t=\phi(\phi X_{t-2}+W_{t-1})+W_t=\phi^2X_{t-2}+\phi W_{t-1}+W_t
$$
$$
X_t=\phi^2(\phi X_{t-3}+W_{t-2})+\phi W_{t-1}+W_t=\phi^3X_{t-3}+\phi^2W_{t-2}+\phi W_{t-1}+W_t
$$
$$
X_t=\phi^3(\phi X_{t-4}+W_{t-3})+\phi^2W_{t-2}+\phi W_{t-1}+W_t=\phi^4X_{t-4}+\phi^3W_{t-3}+\phi^2W_{t-2}+\phi W_{t-1}+W_t
$$
$$
\ldots\implies\boxed{X_t=\sum_{j=0}^t\phi^jW_{t-j}}
$$
for any $t=0,1,\ldots$.

(b) Find the $E[X_t]$.

$$
\mathbb{E}(X_t)=\mathbb{E}(\sum_{j=0}^t\phi^jW_{t-j})=\sum_{j=0}^t\mathbb{E}(\phi^jW_{t-j})=\sum_{j=0}^t\phi^j\mathbb{E}(W_{t-j})
$$
$$
\mathbb{E}(W_{t-j})=0 \quad \forall j\implies\boxed{\mathbb{E}(X_t)=0}
$$

(c) Show that, for $t=0,1,\dots$,

$$Var (X_t) = \frac{\sigma_w^2}{1-\phi^2} (1-\phi^{2(t+1)})$$
$$
Var(X_t)=Var(\sum_{j=0}^t\phi^jW_{t-j})=\sum_{j=0}^tVar(\phi^jW_{t-j})
$$
$$
=\sigma^2_w(1+\phi^2+\phi^4+\phi^6+\ldots+\phi^t)
$$
$$
\implies  Partial \quad Geometric \quad Series \implies (1+x+x^2+\ldots+x^n)=\frac{1-x^{n+1}}{1-x}
$$
$$
\implies \boxed{Var(X_t)=\frac{\sigma^2_w}{1-\phi^2}(1-\phi^{2(t+1)})}
$$

(d) Show that, for $h\geq 0$, 

$$Cov(X_{t+h},X_t)=\phi^h Var(X_t)$$
$$
\gamma_X(h)=Cov(X_{t+h},X_t)=Cov(\sum_{j=0}^t\phi^jW_{t+h-j},\sum_{k=0}^t\phi^kW_{t-k})
$$
$$
=Cov(\phi^hW_t+\phi^{h+1}W_{t-1}+\phi^{h+2}W_{t-2}+\ldots+\phi^{h+t}W_h,W_t+\phi W_{t-1}+\phi^2W_{t-2}+\ldots+\phi^tW_0)
$$
$$
=(\phi^h+\phi^{h+2}+\phi^{h+4}+\ldots+\phi^{h+t})\sigma^2_w
$$
$$
=\phi^h\frac{\sigma^2_w}{1-\phi^2}(1-\phi^{2(t+1)})=\phi^hVar(X_t)
$$
$$
\implies \boxed{Cov(X_{t+h},X_t)=\phi^hVar(X_t)}
$$

(e) Is $X_t$ stationary?

$X_t$ is **NOT** stationary as the autocovariance function depends on the time $t$.

(f) Now suppose $X_0=\frac{W_0}{\sqrt{1-\phi^2}}$. Is this process stationary?

No, $X_t$ is still not stationary. The only difference would be that the value of $Var(X_t)$ at $t=0$ would change, but for $t=1,2,\dots$ the $Var(X_t)$ would be the same as part c. We are just scaling the initial data point. Therefore $Var(X_t)$ would still depend on the time $t$, meaning the process is not stationary.

---

### Question 5. (Grad only)

Show that a time series model $$X_t = \phi_1 X_{t-1}+\phi_2 X_{t-2} +W_t$$ is causal if and only if 

$$\phi_1+\phi_2 <1, \quad \phi_2 - \phi_1<1, \quad |\phi_2|<1.$$

$$
X_t-\phi_1X_{t-1}-\phi_2X_{t-2}=W_t
$$
$$
(1-\phi_2B-\phi_2B^2)X_t=W_t
$$
$$
1-\phi_2B-\phi_2B^2=0
$$
$$
\implies B=\frac{\phi_1\pm\sqrt{\phi^2_1+4\phi_2}}{-2\phi_2}
$$

\newpage

1.

$$
\frac{\phi_1+\sqrt{\phi^2_1+4\phi_2}}{-2\phi_2}>1
$$
$$
\phi_1+\sqrt{\phi^2_1+4\phi_2}<-2\phi_2
$$
$$
\sqrt{\phi^2_1+4\phi_2}<-2\phi_2-\phi_1
$$
$$
\phi^2_1+4\phi_2>4\phi^2_2+4\phi_1\phi_2+\phi^2_1
$$
$$
\implies\boxed{\phi_1+\phi_2<1}
$$

2.

$$
\frac{\phi_1-\sqrt{\phi^2_1+4\phi_2}}{-2\phi_2}<-1
$$
$$
\phi_1-\sqrt{\phi^2_1+4\phi_2}>2\phi_2
$$
$$
\phi_1-2\phi_2>\sqrt{\phi^2_1+4\phi_2}
$$
$$
4\phi^2_2-4\phi_1\phi_2+\phi^2_1<\phi^2_1+4\phi_2
$$
$$
\implies\boxed{\phi_2-\phi_1<1}
$$

3.

$$
\begin{cases} \phi_1+\phi_2<1 \\ \phi_2-\phi_1 <1 \end{cases}
$$

- $\phi_2 > 0$

$$
\implies 2\phi_2 < 2 \implies\phi_2<1
$$

- $\phi_2 < 0$

$$
\implies 2\phi_2>-2 \implies \phi_2>-1
$$
$$
\implies \boxed{|\phi_2| <1}
$$
For $X_t$ to be causal, we need all of the roots of the characteristic polynomial to be outside of the unit circle. This is true when $\phi_1+\phi_2<1$, $\phi_2-\phi_1<1$, and $|\phi_2|<1$. Therefore $X_t$ is causal if and only if all the three conditions are satisfied.