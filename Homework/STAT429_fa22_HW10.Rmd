---
title: "HW 10"
author: "Name: Paul Holaway, NetID: paulch2"
date: 'Due: 11/3/2022 11:59pm'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(xts)
library(astsa)
library(latex2exp)
library(tseries)
library(fpp2)
```
```{r}
#Custom Function for Creating Training and Testing Data
ts.train.test = function(data, freq){
  total.length = length(data)
  test.length = round(total.length * 0.2, 0)
  train.length = total.length - test.length
  data.test = data[train.length:total.length]
  data.train = data[1:(train.length - 1)]
  data.test = ts(data.test, start = time(data)[train.length], frequency = freq)
  data.train = ts(data.train, start = time(data)[1], frequency = freq)
  x = list(data.train, data.test)
  names(x) <- c("train","test")
  return(x)
}
```

### Question 1

```{r, warning=FALSE}
###Creating Training and Testing Data for UnempRate###
UnempRate.train = ts.train.test(UnempRate, 12)$train
UnempRate.test = ts.train.test(UnempRate, 12)$test
```

### Plots

```{r}
par(mfrow = c(3,3))
tsplot(UnempRate.train)
tsplot(diff(UnempRate.train, 12), ylab = TeX(r"($\nabla_{12}$ UnempRate.train)"))
tsplot(diff(diff(UnempRate.train, 12)), ylab = TeX(r"($\nabla\nabla_{12}$ UnempRate.train)"))
acf(UnempRate.train, lag.max = 50)
acf(diff(UnempRate.train, 12), lag.max = 50)
acf(diff(diff(UnempRate.train, 12)), lag.max = 50)
pacf(UnempRate.train, ylab = "PACF", lag.max = 50)
pacf(diff(UnempRate.train, 12), ylab = "PACF", lag.max = 50)
pacf(diff(diff(UnempRate.train, 12)), ylab = "PACF", lag.max = 50)
```

### Tests

```{r, warning=FALSE}
#1
adf.test(UnempRate.train)
kpss.test(UnempRate.train)
#Power Transformation?
BoxCox.lambda(UnempRate.train)
#2; D = 1
adf.test(diff(UnempRate.train, 12))
kpss.test(diff(UnempRate.train, 12))
#3; d = 1, D = 1
adf.test(diff(diff(UnempRate.train, 12)))
kpss.test(diff(diff(UnempRate.train, 12)))
```

\newpage

### Modeling

```{r}
model1.1 = sarima(UnempRate.train, p = 3, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE)
model1.1$ttable
model1.2 = sarima(UnempRate.train, p = 2, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE)
model1.2$ttable
###Testing for Autocorrelations###
#p = 3
Box.test(model1.1$fit$residuals, lag = 25, fitdf = 0)
#p = 2
Box.test(model1.2$fit$residuals, lag = 25, fitdf = 0)
```

### Predictions

```{r}
par(mfrow = c(2,2))
model1.1F = sarima.for(UnempRate.train, p = 3, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE, n.ahead = length(UnempRate.test))
model1.2F = sarima.for(UnempRate.train, p = 2, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE, n.ahead = length(UnempRate.test))
################################################################################
plot(1948:2018,rep(0,71),col = "white", ylim = c(-1,12), xlab = "Year", 
     ylab = "Unemployment Rate", main = TeX(r"(SARIMA(3,1,0)$\times$(0,1,1)$_{12}$)"))
grid()
box()
lines(UnempRate.train)
lines(model1.1F$pred, col = "red")
plot(1948:2018,rep(0,71),col = "white", ylim = c(-1,12), xlab = "Year", 
     ylab = "Unemployment Rate", main = TeX(r"(SARIMA(2,1,0)$\times$(0,1,1)$_{12}$)"))
grid()
box()
lines(UnempRate.train)
lines(model1.2F$pred, col = "red")
#Accuracy
#p = 3
accuracy(object = model1.1F$pred, x = UnempRate.test)
#p = 2
accuracy(object = model1.2F$pred, x = UnempRate.test)
```

### Final Model

$$
\boxed{\text{SARIMA}(2,1,0)\times(0,1,1)_{12}}
$$

When first looking at the data, there appears to be a seasonal trend present. After running both `adf.test()` and `kpss.test()` I decided that there was indeed some kind of trend. While the p-value for the ADF-Test was below 0.05, it was 0.041 which was close and the KPSS-Test p-value was 0.01. Therefore I did a seasonal difference of the data and noticed that the data still looked like there was some sort of trend, however, both the ADF-Test and KPSS-Test did not show evidence of the data not being stationary. The Box-Cox test also output an optimal $\lambda\approx `r round(BoxCox.lambda(UnempRate.train), 4)`$, which is close to 1, so I did not see any reason to perform a transformation. After doing non-seasonal difference, the data looked much closer to white noise and the ACF and PACF were both easier to distinguish orders for the parameters. We can see that the ACF cuts of after seasonal lag 1 and the PACF tails off for seasonal lags, suggesting $P = 0\text{ and } Q = 1$. For the non-seasonal part, we can see that the ACF tails off and the PACF cuts off at lag 3, but lag 3 is barely significant. Therefore I ran two different models. One with $p = 3 \text{ and } q = 0$ and the other with $p = 2 \text{ and } q = 0$. In either case, all of the parameters in the models were statistically significant, the time series plots of the residuals are white noise like, the ACF of the residuals shows that the vast majority are statistically zero, the Normal QQ-Plot looks good (except for a few outliers at the tail ends), and for the most part there does not appear to be autocorrelations between observations. We can confirm this using the Box-Pierce test as we fail to reject the null hypotheses for both that there is no autocorrelation. As both models were similar in all of the diagnostics, AIC, and BIC, I ended up choosing the one with the lower RMSE value as the best model.

### Question 2. 

```{r}
#Creating Training and Testing Data for birth
birth.train = ts.train.test(birth, 12)$train
birth.test = ts.train.test(birth, 12)$test
```

### Plots

```{r}
par(mfrow = c(3,3))
tsplot(birth.train)
tsplot(diff(log(birth.train), 12), ylab = TeX(r"($\nabla_{12}$ $\ln(birth.train)$)"))
tsplot(diff(diff(log(birth.train), 12)), ylab = TeX(r"($\nabla\nabla_{12}$ $\ln(birth.train)$)"))
acf(birth.train, lag.max = 50)
acf(diff(log(birth.train), 12), lag.max = 50)
acf(diff(diff(log(birth.train), 12)), lag.max = 50)
pacf(birth.train, ylab = "PACF", lag.max = 50)
pacf(diff(log(birth.train), 12), ylab = "PACF")
pacf(diff(diff(log(birth.train), 12)), ylab = "PACF", lag.max = 50)
```

### Tests

```{r, warning=FALSE}
#1
adf.test(birth.train)
kpss.test(birth.train)
#Power Transformation?
BoxCox.lambda(birth.train)
#Retesting with log-transformation
adf.test(log(birth.train))
kpss.test(log(birth.train))
#2; D = 1
adf.test(diff(log(birth.train), 12))
kpss.test(diff(log(birth.train), 12))
#3; d = 1, D = 1
adf.test(diff(diff(log(birth.train), 12)))
kpss.test(diff(diff(log(birth.train), 12)))
```

### Modeling

```{r}
model2.1 = sarima(log(birth.train), p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE)
model2.1$ttable
model2.2 = sarima(log(birth.train), p = 1, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE)
model2.2$ttable
model2.3 = sarima(log(birth.train), p = 3, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE)
model2.3$ttable
###Testing for Autocorrelations###
#p = 0
Box.test(model2.1$fit$residuals, lag = 25, fitdf = 0)
#p = 1
Box.test(model2.2$fit$residuals, lag = 25, fitdf = 0)
#p = 3
Box.test(model2.3$fit$residuals, lag = 25, fitdf = 0)
```

### Predictions

```{r}
par(mfrow = c(2,3))
model2.1F = sarima.for(log(birth.train), p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE, n.ahead = length(birth.test))
model2.2F = sarima.for(log(birth.train), p = 1, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE, n.ahead = length(birth.test))
model2.3F = sarima.for(log(birth.train), p = 3, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 12, 
                  no.constant = TRUE, n.ahead = length(birth.test))
################################################################################
plot(1948:1979,rep(0,32), col = "white", ylim = c(200,400), xlab = "Year", 
     ylab = "Birth Rate", main = TeX(r"(SARIMA(0,1,1)$\times$(0,1,1)$_{12}$)"))
grid()
box()
lines(birth.train)
lines(exp(model2.1F$pred), col = "red")
plot(1948:1979,rep(0,32), col = "white", ylim = c(200,400), xlab = "Year", 
     ylab = "Birth Rate", main = TeX(r"(SARIMA(1,1,1)$\times$(0,1,1)$_{12}$)"))
grid()
box()
lines(birth.train)
lines(exp(model2.2F$pred), col = "red")
plot(1948:1979,rep(0,32), col = "white", ylim = c(200,400), xlab = "Year", 
     ylab = "Birth Rate", main = TeX(r"(SARIMA(3,1,1)$\times$(0,1,1)$_{12}$)"))
grid()
box()
lines(birth.train)
lines(exp(model2.3F$pred), col = "red")
###Accuracy###
#p = 0
accuracy(object = model2.1F$pred, x = log(birth.test))
#p = 1
accuracy(object = model2.2F$pred, x = log(birth.test))
#p = 3
accuracy(object = model2.3F$pred, x = log(birth.test))
```
\newpage

### Final Model

$$
\boxed{\text{SARIMA}(3,1,1)\times(0,1,1)_{12}}
$$
When first looking at the data, there appears to be both a seasonal and non-seasonal trend present. However, the Box-Cox test output an optimal $\lambda\approx `r round(BoxCox.lambda(birth.train), 4)`$, which is close to 0, so I performed a log-transformation on the data. After running both `adf.test()` and `kpss.test()` I decided that there was indeed some kind of trend. The p-value for the ADF-Test was above 0.05, but the KPSS-Test p-value was 0.01. Therefore I did a seasonal difference of the data to see what would happen. I then noticed that the data was better, but still showed some sort of trend. The ADF-Test showed signs of a trend being present while KPSS-Test did not. After doing non-seasonal difference, the data looked much closer to white noise and the ACF and PACF were both easier to distinguish orders for the parameters. We can see that the ACF cuts of after seasonal lag 1 and the PACF tails off for seasonal lags, suggesting $P = 0\text{ and } Q = 1$. For the non-seasonal part, we can see that the ACF cuts off at lag 1 and the PACF tails off, with lags 1-4 being significant. Therefore I ran three different models. One with $p = 0 \text{ and } q = 1$, $p = 1 \text{ and } q = 1$, and the other with $p = 3 \text{ and } q = 1$. $p = 2$ resulted in almost all of the coefficients being insignificant. In all cases, the time series plot, Normal QQ-Plot, and ACF of the residuals all looked about the same. The plot of the residuals was white noise like, the ACF was almost all statistically zero, and the Normal QQ-Plots all followed the line close. The AIC and BIC were all close to each other with $p=3$ having the lowest. The RMSE of $p=3$ was also the smallest and it was the only one that showed no signs of autocorrelation between observations in both the Box-Pierce test and Ljung-Box test. Therefore, I will choose the model with $p=3$ for my final model.

### Question 3. 

```{r}
#Creating Training and Testing Data for gtemp_land
gtemp_land.train = ts.train.test(gtemp_land, 1)$train
gtemp_land.test = ts.train.test(gtemp_land, 1)$test
```

### Plots

```{r}
par(mfrow = c(3,3))
tsplot(gtemp_land.train)
tsplot(diff(gtemp_land.train), ylab = TeX(r"($\nabla$ gtemp_land.train)"))
tsplot(diff(diff(gtemp_land.train), 5), ylab = TeX(r"($\nabla\nabla_{12}$ gtemp_land.train)"))
acf(gtemp_land.train, lag.max = 50)
acf(diff(diff(gtemp_land.train), 5), lag.max = 50)
acf(diff(diff(gtemp_land.train)), lag.max = 50)
pacf(gtemp_land.train, ylab = "PACF", lag.max = 50)
pacf(diff(gtemp_land.train), ylab = "PACF", lag.max = 50)
pacf(diff(diff(gtemp_land.train), 5), ylab = "PACF", lag.max = 50)
```

### Tests

```{r, warning=FALSE}
#1
adf.test(gtemp_land.train)
kpss.test(gtemp_land.train)
#2; d = 1
adf.test(diff(gtemp_land.train))
kpss.test(diff(gtemp_land.train))
#3; d = 1, D = 1
adf.test(diff(diff(gtemp_land.train), 5))
kpss.test(diff(diff(gtemp_land.train), 5))
```

### Modeling

```{r}
model3.1 = sarima(gtemp_land.train, p = 1, d = 1, q = 0, P = 1, D = 1, Q = 0, S = 5,
                  no.constant = TRUE)
model3.1$ttable
model3.2 = sarima(gtemp_land.train, p = 1, d = 1, q = 0, P = 2, D = 1, Q = 0, S = 5,
                  no.constant = TRUE)
model3.2$ttable
model3.3 = sarima(gtemp_land.train, p = 3, d = 1, q = 0, P = 1, D = 1, Q = 0, S = 5,
                  no.constant = TRUE)
model3.3$ttable
model3.4 = sarima(gtemp_land.train, p = 3, d = 1, q = 0, P = 2, D = 1, Q = 0, S = 5,
                  no.constant = TRUE)
model3.4$ttable
###Testing for Autocorrelations###
#p = 1, P = 1
Box.test(model3.1$fit$residuals, lag = 25, fitdf = 0)
#p = 1, P = 2
Box.test(model3.2$fit$residuals, lag = 25, fitdf = 0)
#p = 3, P = 1
Box.test(model3.3$fit$residuals, lag = 25, fitdf = 0)
#p = 3, P = 2
Box.test(model3.4$fit$residuals, lag = 25, fitdf = 0)
```

### Predictions

```{r}
par(mfrow = c(2,2))
model3.1F = sarima.for(gtemp_land.train, p = 1, d = 1, q = 0, P = 1, D = 1, Q = 0, S = 5, 
                       no.constant = TRUE, n.ahead = length(gtemp_land.test))
model3.2F = sarima.for(gtemp_land.train, p = 1, d = 1, q = 0, P = 2, D = 1, Q = 0, S = 5,
                       no.constant = TRUE, n.ahead = length(gtemp_land.test))
################################################################################
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.9,2), xlab = "Year", 
     ylab = "Global Mean Land Temp. (Celcius)", 
     main = TeX(r"(SARIMA(1,1,0)$\times$(1,1,0)$_{5}$)"))
grid()
box()
lines(gtemp_land.train)
lines(model3.1F$pred, col = "red")
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.9,2), xlab = "Year", 
     ylab = "Global Mean Land Temp. (Celcius)", 
     main = TeX(r"(SARIMA(1,1,0)$\times$(2,1,0)$_{5}$)"))
grid()
box()
lines(gtemp_land.train)
lines(model3.2F$pred, col = "red")
model3.3F = sarima.for(gtemp_land.train, p = 3, d = 1, q = 0, P = 1, D = 1, Q = 0, S = 5, 
                       no.constant = TRUE, n.ahead = length(gtemp_land.test))
model3.4F = sarima.for(gtemp_land.train, p = 3, d = 1, q = 0, P = 2, D = 1, Q = 0, S = 5, 
                       no.constant = TRUE, n.ahead = length(gtemp_land.test))
################################################################################
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.9,2), xlab = "Year", 
     ylab = "Global Mean Land Temp. (Celcius)", 
     main = TeX(r"(SARIMA(3,1,0)$\times$(1,1,0)$_{5}$)"))
grid()
box()
lines(gtemp_land.train)
lines(model3.3F$pred, col = "red")
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.9,2), xlab = "Year", 
     ylab = "Global Mean Land Temp. (Celcius)", 
     main = TeX(r"(SARIMA(3,1,0)$\times$(2,1,0)$_{5}$)"))
grid()
box()
lines(gtemp_land.train)
lines(model3.4F$pred, col = "red")
###Accuracy###
accuracy(object = model3.1F$pred, x = gtemp_land.test)
accuracy(object = model3.2F$pred, x = gtemp_land.test)
accuracy(object = model3.3F$pred, x = gtemp_land.test)
accuracy(object = model3.4F$pred, x = gtemp_land.test)
```

### Final Model

$$
\boxed{\text{SARIMA}(3,1,0)\times(2,1,0)_{5}}
$$

When first looking at the data, there appears to be a non-seasonal trend present. After running both `adf.test()` and `kpss.test()` I decided that there was indeed some kind of trend. The p-value for the ADF-Test was above 0.05, but the KPSS-Test p-value was 0.01. Therefore I did a difference of the data to see what would happen. I then noticed that the data was better, but when creating models, the predictions were not good. I ended up doing a seasonal difference of 5 years (10 didn't look great) and the ACF and PACF was more distinct. The ADF-Test and KPSS-Test both remained as no evidence of a trend being present. We can see that the ACF tails off and the PACF cuts off for seasonal lag 1 and is borderline for seasonal lag 2. We then see non-seasonal lags are significant for lags 1 and 3 on the PACF, suggesting $P \in [1,2]$ and $p \in [1,3]$. I first used $p=1$ and $P=1$, but it showed autocorrelation between observations. $P=2$ and $p = 3\text{ and } P = 1$ also showed autocorrelations between observations. While the Box-Pierce test did not show up anything, the Ljung-Box test did. The final model with $p = 3\text{ and } P = 2$ was the one that did not and had great diagnostics. Its residual time series plot looks similar to white noise, the ACF of the residuals does not have any significant lags, the Normal QQ-Plot follows the line, and to put the icing on the cake, all coefficient estimates are significant. It also has the lowest AIC and BIC of the four models. It also has the lowest RMSE, so that is why I would choose this as the final model.

### Question 4. 

```{r}
gtemp_ocean.train = ts.train.test(gtemp_ocean, 1)$train
gtemp_ocean.test = ts.train.test(gtemp_ocean, 1)$test
```

### Plots

```{r}
par(mfrow = c(3,3))
tsplot(gtemp_ocean.train)
tsplot(diff(gtemp_ocean.train), ylab = TeX(r"($\nabla$ gtemp_land.train)"))
tsplot(diff(diff(gtemp_ocean.train), 5), ylab = TeX(r"($\nabla\nabla_{5}$ gtemp_land.train)"))
acf(gtemp_ocean.train, lag.max = 50)
acf(diff(gtemp_ocean.train), lag.max = 50)
acf(diff(diff(gtemp_ocean.train), 5), lag.max = 50)
pacf(gtemp_ocean.train, ylab = "PACF", lag.max = 50)
pacf(diff(gtemp_ocean.train), ylab = "PACF", lag.max = 50)
pacf(diff(diff(gtemp_ocean.train), 5), lag.max = 50)
```

### Tests

```{r warning=FALSE}
#1
adf.test(gtemp_ocean.train)
kpss.test(gtemp_ocean.train)
#2; d = 1
adf.test(diff(gtemp_ocean.train))
kpss.test(diff(gtemp_ocean.train))
#3; d = 1, D = 1
adf.test(diff(diff(gtemp_ocean.train), 5))
kpss.test(diff(diff(gtemp_ocean.train), 5))
```

### Modeling

```{r}
model4.1 = sarima(gtemp_ocean.train, p = 0, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 5,
                  no.constant = TRUE)
model4.1$ttable
model4.2 = sarima(gtemp_ocean.train, p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 5,
                  no.constant = TRUE)
model4.2$ttable
model4.3 = sarima(gtemp_ocean.train, p = 0, d = 1, q = 2, P = 0, D = 1, Q = 1, S = 5,
                  no.constant = TRUE)
model4.3$ttable
###Testing for Autocorrelations###
#q = 1
Box.test(model4.1$fit$residuals, lag = 25, fitdf = 0)
#q = 1
Box.test(model4.2$fit$residuals, lag = 25, fitdf = 0)
#q = 3
Box.test(model4.3$fit$residuals, lag = 25, fitdf = 0)
```

### Predictions

```{r}
par(mfrow = c(2,3))
model4.1F = sarima.for(gtemp_ocean.train, p = 0, d = 1, q = 0, P = 0, D = 1, Q = 1, S = 5,
                       no.constant = TRUE, n.ahead = length(gtemp_ocean.test))
model4.2F = sarima.for(gtemp_ocean.train, p = 0, d = 1, q = 1, P = 0, D = 1, Q = 1, S = 5,
                       no.constant = TRUE, n.ahead = length(gtemp_ocean.test))
model4.3F = sarima.for(gtemp_ocean.train, p = 0, d = 1, q = 2, P = 0, D = 1, Q = 1, S = 5,
                       no.constant = TRUE, n.ahead = length(gtemp_ocean.test))
################################################################################
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.6,0.5), xlab = "Year", 
     ylab = "Global Mean Ocean Temp. (Celcuius)",
     main = TeX(r"(SARIMA(0,1,0)$\times$(0,1,1)$_{5}$)"))
grid()
box()
lines(gtemp_ocean.train)
lines(model4.1F$pred, col = "red")
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.6,0.5), xlab = "Year", 
     ylab = "Global Mean Ocean Temp. (Celcuius)",
     main = TeX(r"(SARIMA(0,1,1)$\times$(0,1,1)$_{5}$)"))
grid()
box()
lines(gtemp_ocean.train)
lines(model4.2F$pred, col = "red")
plot(1880:2017,rep(0,138), col = "white", ylim = c(-0.6,0.5), xlab = "Year", 
     ylab = "Global Mean Ocean Temp. (Celcuius)",
     main = TeX(r"(SARIMA(0,1,2)$\times$(0,1,1)$_{5}$)"))
grid()
box()
lines(gtemp_ocean.train)
lines(model4.3F$pred, col = "red")
###Accuracy###
accuracy(object = model4.1F$pred, x = gtemp_ocean.test)
accuracy(object = model4.2F$pred, x = gtemp_ocean.test)
accuracy(object = model4.3F$pred, x = gtemp_ocean.test)
```

### Final Model

$$
\boxed{\text{SARIMA}(0,1,0)\times(0,1,1)_{5}}
$$

When first looking at the data, there appears to be a non-seasonal trend present. After running both `adf.test()` and `kpss.test()` I decided that there was indeed some kind of trend. The p-value for the ADF-Test was above 0.05, but the KPSS-Test p-value was 0.01. Therefore I did a difference of the data to see what would happen. I then noticed that the data was better, but when creating models, the predictions were not good (just like problem 3). I ended up doing a seasonal difference of 5 years (again, 10 didn't look great) and the ACF and PACF was more distinct. The ADF-Test and KPSS-Test both remained as no evidence of a trend being present. We can see that the ACF cuts off at seasonal lag 1 and the PACF tails off. We then see non-seasonal lags are significant for lag 2 on the ACF, suggesting $Q = 1$ and $q \in [0,2]$. I tried out three different models, one for each of the three potential model orders of $q$. While the Box-Pierce test did not show any autocorrelation, the Ljung-Box test did for the first two models. The other diagnostics such as the standardized residual time series plot, ACF of the residuals, and Normal QQ-Plot were approximately the same for each one and the results showed no signs of any model issues. The final model with $q=2$ showed no signs of autocorrelation and had the lowest AIC and BIC, but the second model had the best RMSE. I ended up deciding to use the first model. It has the second best RMSE and second lowest AIC/BIC. While one test shows it may have autocorrelation between observations, it is borderline so it is close to not having autocorrelation, which is what the Box-Pierce test says. $\hat{\theta}_1$ is not statistically significant in the second model, so I did not think it would make sense to use that one over the first model. The third model also has the highest RMSE of the three, so I did not think it would make sense to use that one either.